{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"PriorPatch","text":"<p>Image forensics without the neural network nonsense.</p>"},{"location":"#what-is-this","title":"What is this?","text":"<p>Tool for detecting fake/edited images using signal processing instead of machine learning. Runs 6 different mathematical tests on image patches and shows you a heatmap of suspicious regions.</p> <p>Why not ML? Because:</p> <ul> <li>You can actually understand what it's doing</li> <li>No GPU needed</li> <li>No training data needed</li> <li>Can't be easily fooled if attacker doesn't know what you're checking</li> <li>Easier to extend and debug</li> </ul> <p>Trade-off: probably not as accurate as the latest deep learning models, but way more transparent.</p>"},{"location":"#what-it-does","title":"What It Does","text":"<p>PriorPatch analyzes images by:</p> <ol> <li>Dividing them into overlapping patches</li> <li>Scoring each patch with multiple forensic detectors</li> <li>Combining scores using ensemble methods</li> <li>Generating visual heatmaps showing suspicious regions</li> </ol> <p>The toolkit includes 6 different detectors examining:</p> <ul> <li>Color channel correlations</li> <li>Spatial consistency</li> <li>Frequency domain characteristics</li> <li>High-frequency noise patterns</li> <li>JPEG compression artifacts</li> <li>Sensor noise (PRNU)</li> </ul>"},{"location":"#quick-example","title":"Quick Example","text":"<p>Command Line:</p> <pre><code>priorpatch analyze --input photo.jpg --outdir results/\n</code></pre> <p>Python API:</p> <pre><code>from priorpatch import Ensemble, load_image, save_heatmap\n\nimg = load_image('photo.jpg')\nensemble = Ensemble.from_config('config/detectors.json')\nheatmap = ensemble.score_image(img)\nsave_heatmap(heatmap, img, 'result.png')\n</code></pre> <p>Output:</p> <ul> <li>Visual heatmap overlay (red = suspicious, blue = normal)</li> <li>JSON summary with scores and metadata</li> </ul>"},{"location":"#use-cases","title":"Use cases","text":"<ul> <li>Check if that viral image is actually real</li> <li>Learn how image forensics works</li> <li>Research detector techniques</li> <li>Build your own forensic tool</li> <li>Educational projects</li> </ul> <p>Don't use this as your only verification method though. It's one tool, not a magic truth detector.</p>"},{"location":"#key-features","title":"Key Features","text":""},{"location":"#multiple-detection-methods","title":"Multiple Detection Methods","text":"<p>Each detector examines different forensic traces:</p> <ul> <li>ColorStats: RGB correlation analysis</li> <li>NeighborConsistency: Spatial prediction anomalies</li> <li>FFT/DCT: Frequency domain analysis</li> <li>ResidualEnergy: High-frequency noise patterns</li> <li>DCTCooccurrence: JPEG artifact analysis</li> <li>PRNU: Sensor noise detection</li> </ul>"},{"location":"#ensemble-approach","title":"Ensemble Approach","text":"<p>Combining multiple detectors:</p> <ul> <li>Reduces false positives</li> <li>Handles diverse manipulation types</li> <li>Provides confidence through redundancy</li> <li>Allows custom weighting</li> </ul>"},{"location":"#visual-heatmaps","title":"Visual Heatmaps","text":"<p>Intuitive visualization:</p> <ul> <li>Color-coded suspicious regions</li> <li>Overlay on original image</li> <li>Customizable transparency and colormap</li> <li>Export as high-resolution PNG</li> </ul>"},{"location":"#configurable-pipeline","title":"Configurable Pipeline","text":"<p>JSON-based configuration:</p> <ul> <li>Enable/disable detectors</li> <li>Set detector weights</li> <li>Adjust patch size and stride</li> <li>No code changes needed</li> </ul>"},{"location":"#getting-started","title":"Getting Started","text":"<ol> <li>Installation - Set up PriorPatch</li> <li>Usage Guide - Learn basic and advanced usage</li> <li>Detector Details - Understand each detector</li> <li>Architecture - Learn the system design</li> <li>API Reference - Full API documentation</li> </ol>"},{"location":"#example-results","title":"Example Results","text":"<p>PriorPatch generates heatmaps like this:</p> <pre><code>Input: Potentially manipulated image\nOutput: Heatmap overlay showing:\n  - Blue/green regions: Normal (low anomaly score)\n  - Yellow/orange: Slightly suspicious\n  - Red: Highly suspicious (high anomaly score)\n</code></pre> <p>The heatmap helps you visually identify:</p> <ul> <li>Spliced regions</li> <li>AI-generated content</li> <li>Retouched/airbrushed areas</li> <li>Copy-pasted objects</li> </ul>"},{"location":"#why-i-made-this","title":"Why I Made This","text":"<p>Mostly for learning. Wanted to understand how image forensics actually works without relying on black-box ML models. Also useful for research baselines and teaching.</p>"},{"location":"#limitations","title":"Limitations","text":"<p>PriorPatch is designed for research and education. Be aware:</p> <ul> <li>Not 100% accurate (no detector is)</li> <li>Can have false positives/negatives</li> <li>Performance varies by manipulation type</li> <li>Should be used with other verification methods</li> <li>Not a replacement for expert forensic analysis</li> </ul>"},{"location":"#links","title":"Links","text":"<ul> <li>Issues - Bug reports, feature requests</li> <li>Contributing - Want to help?</li> </ul>"},{"location":"#license","title":"License","text":"<p>PriorPatch is licensed under the Apache License 2.0.</p>"},{"location":"#citation","title":"Citation","text":"<p>If you use this in research:</p> <pre><code>@software{priorpatch2025,\n  title={PriorPatch},\n  author={Jayashankar VR},\n  year={2025},\n  url={https://github.com/jayashankarvr/priorpatch}\n}\n</code></pre>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#core-classes","title":"Core Classes","text":""},{"location":"api/#ensemble","title":"<code>Ensemble</code>","text":"<p>Main class for managing and running multiple detectors.</p> <pre><code>from priorpatch.core import Ensemble\n</code></pre>"},{"location":"api/#constructor","title":"Constructor","text":"<pre><code>Ensemble(detectors: List[DetectorInterface], weights: Optional[Dict[str, float]] = None)\n</code></pre> <p>Parameters:</p> <ul> <li><code>detectors</code>: List of detector instances</li> <li><code>weights</code>: Optional dictionary mapping detector names to weights (default: all weights = 1.0)</li> </ul>"},{"location":"api/#class-methods","title":"Class Methods","text":""},{"location":"api/#from_configpath-str-ensemble","title":"<code>from_config(path: str) -&gt; Ensemble</code>","text":"<p>Create an ensemble from a JSON configuration file.</p> <pre><code>ensemble = Ensemble.from_config('config/detectors.json')\n</code></pre> <p>Parameters:</p> <ul> <li><code>path</code>: Path to JSON configuration file</li> </ul> <p>Returns:</p> <ul> <li>Configured <code>Ensemble</code> instance</li> </ul> <p>Raises:</p> <ul> <li><code>FileNotFoundError</code>: Configuration file doesn't exist</li> <li><code>ValueError</code>: Invalid detector name in configuration</li> <li><code>json.JSONDecodeError</code>: Malformed JSON</li> </ul>"},{"location":"api/#instance-methods","title":"Instance Methods","text":""},{"location":"api/#score_patchpatch-npndarray-patchresult","title":"<code>score_patch(patch: np.ndarray) -&gt; PatchResult</code>","text":"<p>Score a single image patch using all detectors.</p> <pre><code>result = ensemble.score_patch(patch)\ncombined_score = result.combined\nindividual_scores = result.individual\nfailures = result.failures\n</code></pre> <p>Parameters:</p> <ul> <li><code>patch</code>: Image patch as numpy array (H, W, 3)</li> </ul> <p>Returns:</p> <ul> <li><code>PatchResult</code> dataclass with fields:</li> <li><code>combined</code>: Weighted normalized combined score (float)</li> <li><code>individual</code>: List of raw detector scores</li> <li><code>failures</code>: List of (detector_name, error_message) tuples for failed detectors</li> </ul>"},{"location":"api/#score_imageimg-npndarray-patch_size-int-64-stride-int-32-return_individual-bool-false-unionnpndarray-analysisresult","title":"<code>score_image(img: np.ndarray, patch_size: int = 64, stride: int = 32, return_individual: bool = False) -&gt; Union[np.ndarray, AnalysisResult]</code>","text":"<p>Score an entire image by analyzing overlapping patches.</p> <pre><code># Combined result only\nheatmap = ensemble.score_image(img, patch_size=64, stride=32)\n\n# Combined + individual detector results\nresults = ensemble.score_image(img, patch_size=64, stride=32, return_individual=True)\ncombined = results.combined\nindividual = results.individual\ndetector_names = results.detector_names\n</code></pre> <p>Parameters:</p> <ul> <li><code>img</code>: Input image as numpy array (H, W, 3)</li> <li><code>patch_size</code>: Size of square patches (default: 64)</li> <li><code>stride</code>: Stride for patch extraction (default: 32)</li> <li><code>return_individual</code>: If True, return AnalysisResult with individual detector scores (default: False)</li> </ul> <p>Returns:</p> <ul> <li>If <code>return_individual=False</code>: Heatmap of anomaly scores, normalized to [0, 1], shape (H', W')</li> <li>If <code>return_individual=True</code>: <code>AnalysisResult</code> object with fields:</li> <li><code>combined</code>: Combined heatmap (np.ndarray)</li> <li><code>individual</code>: Dict mapping detector names to their heatmaps</li> <li><code>detector_names</code>: List of detector names</li> </ul> <p>Raises:</p> <ul> <li><code>ValueError</code>: Invalid image dimensions</li> </ul>"},{"location":"api/#utility-functions","title":"Utility Functions","text":""},{"location":"api/#load_imagepath-str-npndarray","title":"<code>load_image(path: str) -&gt; np.ndarray</code>","text":"<p>Load an image from file.</p> <pre><code>from priorpatch.utils import load_image\n\nimg = load_image('path/to/image.jpg')\n</code></pre> <p>Parameters:</p> <ul> <li><code>path</code>: Path to image file</li> </ul> <p>Returns:</p> <ul> <li>Image as numpy array (H, W, 3) in RGB format</li> </ul> <p>Raises:</p> <ul> <li><code>FileNotFoundError</code>: Image file doesn't exist</li> <li><code>IOError</code>: Cannot load image</li> </ul>"},{"location":"api/#save_heatmapheatmap-npndarray-image-npndarray-outpath-str-alpha-float-045-cmap-str-jet-none","title":"<code>save_heatmap(heatmap: np.ndarray, image: np.ndarray, outpath: str, alpha: float = 0.45, cmap: str = 'jet') -&gt; None</code>","text":"<p>Save a heatmap overlay visualization.</p> <pre><code>from priorpatch.utils import save_heatmap\n\nsave_heatmap(heatmap, img, 'output.png', alpha=0.5, cmap='hot')\n</code></pre> <p>Parameters:</p> <ul> <li><code>heatmap</code>: 2D array of anomaly scores (H_heat, W_heat)</li> <li><code>image</code>: Original image (H, W, 3)</li> <li><code>outpath</code>: Output file path</li> <li><code>alpha</code>: Overlay transparency, 0=transparent, 1=opaque (default: 0.45)</li> <li><code>cmap</code>: Matplotlib colormap name (default: 'jet')</li> </ul> <p>Raises:</p> <ul> <li><code>ValueError</code>: Invalid input dimensions</li> <li><code>IOError</code>: Cannot write file</li> </ul>"},{"location":"api/#validate_pathpath-str-must_exist-bool-false-path","title":"<code>validate_path(path: str, must_exist: bool = False) -&gt; Path</code>","text":"<p>Validate and sanitize a file path.</p> <pre><code>from priorpatch.utils import validate_path\n\nsafe_path = validate_path('user/input/path.jpg', must_exist=True)\n</code></pre> <p>Parameters:</p> <ul> <li><code>path</code>: Path to validate</li> <li><code>must_exist</code>: Require path to exist (default: False)</li> </ul> <p>Returns:</p> <ul> <li>Validated <code>Path</code> object</li> </ul> <p>Raises:</p> <ul> <li><code>ValueError</code>: Invalid path</li> <li><code>FileNotFoundError</code>: Path doesn't exist (if <code>must_exist=True</code>)</li> </ul>"},{"location":"api/#detector-interface","title":"Detector Interface","text":""},{"location":"api/#detectorinterface","title":"<code>DetectorInterface</code>","text":"<p>Abstract base class for all detectors.</p> <pre><code>from priorpatch.detectors.base import DetectorInterface\nfrom priorpatch.detectors.registry import register_detector\nimport numpy as np\n\n@register_detector\nclass MyDetector(DetectorInterface):\n    name = 'my_detector'\n\n    def score(self, patch: np.ndarray) -&gt; float:\n        # Your detection logic here\n        return anomaly_score\n</code></pre>"},{"location":"api/#abstract-methods","title":"Abstract Methods","text":""},{"location":"api/#scorepatch-npndarray-float","title":"<code>score(patch: np.ndarray) -&gt; float</code>","text":"<p>Compute anomaly score for an image patch.</p> <p>Parameters:</p> <ul> <li><code>patch</code>: Image patch as numpy array (H, W, 3)</li> </ul> <p>Returns:</p> <ul> <li>Anomaly score as float (higher = more suspicious)</li> </ul> <p>Note: The score range is detector-specific and will be normalized by the ensemble.</p>"},{"location":"api/#registry-functions","title":"Registry Functions","text":""},{"location":"api/#register_detectorcls-typedetectorinterface-typedetectorinterface","title":"<code>register_detector(cls: Type[DetectorInterface]) -&gt; Type[DetectorInterface]</code>","text":"<p>Decorator to register a detector class.</p> <pre><code>from priorpatch.detectors.registry import register_detector\n\n@register_detector\nclass MyDetector(DetectorInterface):\n    name = 'my_detector'\n    # ...\n</code></pre> <p>Parameters:</p> <ul> <li><code>cls</code>: Detector class to register</li> </ul> <p>Returns:</p> <ul> <li>Same class (allows use as decorator)</li> </ul> <p>Raises:</p> <ul> <li><code>ValueError</code>: Detector name already registered</li> </ul>"},{"location":"api/#get_detector_classname-str-optionaltypedetectorinterface","title":"<code>get_detector_class(name: str) -&gt; Optional[Type[DetectorInterface]]</code>","text":"<p>Retrieve a detector class by name.</p> <pre><code>from priorpatch.detectors.registry import get_detector_class\n\nDetectorClass = get_detector_class('color_stats')\ndetector = DetectorClass()\n</code></pre> <p>Parameters:</p> <ul> <li><code>name</code>: Detector name</li> </ul> <p>Returns:</p> <ul> <li>Detector class if found, <code>None</code> otherwise</li> </ul>"},{"location":"api/#built-in-detectors","title":"Built-in Detectors","text":""},{"location":"api/#colorstatsdetector","title":"<code>ColorStatsDetector</code>","text":"<p>Analyzes RGB channel correlations.</p> <ul> <li>Name: <code>'color_stats'</code></li> <li>Algorithm: Computes deviation from expected RGB correlation matrix</li> <li>Best for: Detecting unnatural color relationships</li> </ul>"},{"location":"api/#neighborconsistencydetector","title":"<code>NeighborConsistencyDetector</code>","text":"<p>Analyzes spatial prediction consistency.</p> <ul> <li>Name: <code>'neighbor_consistency'</code></li> <li>Algorithm: Compares pixels to 8-neighbor average</li> <li>Best for: Detecting splice boundaries, local inconsistencies</li> </ul>"},{"location":"api/#fftdctdetector","title":"<code>FFTDCTDetector</code>","text":"<p>Examines frequency domain characteristics.</p> <ul> <li>Name: <code>'fft_dct'</code></li> <li>Algorithm: Analyzes radial power spectrum and power-law slope</li> <li>Best for: Detecting resampling, compression artifacts</li> </ul>"},{"location":"api/#residualenergydetector","title":"<code>ResidualEnergyDetector</code>","text":"<p>Measures high-frequency residual energy.</p> <ul> <li>Name: <code>'residual_energy'</code></li> <li>Algorithm: Computes energy after Gaussian smoothing</li> <li>Best for: Detecting smoothed/blurred regions</li> </ul>"},{"location":"api/#dctcoocdetector","title":"<code>DCTCoocDetector</code>","text":"<p>Analyzes DCT coefficient patterns.</p> <ul> <li>Name: <code>'dct_cooccurrence'</code></li> <li>Algorithm: Examines variance in 8x8 block DC coefficients</li> <li>Best for: Detecting JPEG compression inconsistencies</li> </ul>"},{"location":"api/#prnuwaveletdetector","title":"<code>PRNUWaveletDetector</code>","text":"<p>Sensor noise pattern detector using wavelet denoising.</p> <ul> <li>Name: <code>'prnu_wavelet'</code></li> <li>Algorithm: Extracts PRNU via wavelet-based noise extraction</li> <li>Best for: AI-generated image detection, source camera identification</li> </ul>"},{"location":"api/#eladetector","title":"<code>ELADetector</code>","text":"<p>Error Level Analysis detector.</p> <ul> <li>Name: <code>'ela'</code></li> <li>Algorithm: JPEG recompression analysis</li> <li>Best for: Detecting JPEG manipulation, spliced images</li> </ul>"},{"location":"api/#benfordlawdetector","title":"<code>BenfordLawDetector</code>","text":"<p>Statistical distribution detector.</p> <ul> <li>Name: <code>'benford_law'</code></li> <li>Algorithm: First-digit distribution of DCT coefficients</li> <li>Best for: General manipulation detection (~90% F1-score)</li> </ul>"},{"location":"api/#cfaartifactdetector","title":"<code>CFAArtifactDetector</code>","text":"<p>Camera sensor artifact detector.</p> <ul> <li>Name: <code>'cfa_artifact'</code></li> <li>Algorithm: Detects Bayer demosaicing patterns</li> <li>Best for: AI detection (highest discriminative power)</li> </ul>"},{"location":"api/#configuration-format","title":"Configuration Format","text":""},{"location":"api/#json-configuration-schema","title":"JSON Configuration Schema","text":"<pre><code>{\n  \"enabled_detectors\": [\n    \"color_stats\",\n    \"neighbor_consistency\",\n    \"fft_dct\",\n    \"residual_energy\",\n    \"dct_cooccurrence\",\n    \"benford_law\",\n    \"cfa_artifact\",\n    \"ela\"\n  ],\n  \"detector_weights\": {\n    \"color_stats\": 1.0,\n    \"neighbor_consistency\": 1.2,\n    \"fft_dct\": 1.5,\n    \"residual_energy\": 1.0,\n    \"dct_cooccurrence\": 1.1,\n    \"benford_law\": 1.8,\n    \"cfa_artifact\": 2.0,\n    \"ela\": 1.2\n  }\n}\n</code></pre> <p>Fields:</p> <ul> <li><code>enabled_detectors</code>: List of detector names to use</li> <li><code>detector_weights</code>: Optional weights for each detector (default: 1.0)</li> </ul>"},{"location":"api/#examples","title":"Examples","text":""},{"location":"api/#basic-usage","title":"Basic Usage","text":"<pre><code>from priorpatch import Ensemble, load_image, save_heatmap\n\n# Load image\nimg = load_image('image.jpg')\n\n# Create ensemble from config\nensemble = Ensemble.from_config('config/detectors.json')\n\n# Analyze image\nheatmap = ensemble.score_image(img, patch_size=64, stride=32)\n\n# Save visualization\nsave_heatmap(heatmap, img, 'result.png')\n</code></pre>"},{"location":"api/#custom-detector-weights","title":"Custom Detector Weights","text":"<pre><code>from priorpatch.core import Ensemble\nfrom priorpatch.detectors.registry import get_detector_class\n\n# Manually create detectors with custom weights\ndetectors = [\n    get_detector_class('color_stats')(),\n    get_detector_class('fft_dct')(),\n]\n\nweights = {\n    'color_stats': 2.0,  # Double weight\n    'fft_dct': 0.5,      # Half weight\n}\n\nensemble = Ensemble(detectors, weights)\n</code></pre>"},{"location":"api/#analyzing-specific-regions","title":"Analyzing Specific Regions","text":"<pre><code># Extract a specific region\nregion = img[100:200, 150:250]  # y:y+h, x:x+w\n\n# Score the region\nresult = ensemble.score_patch(region)\n\nprint(f\"Combined score: {result.combined:.4f}\")\nfor i, s in enumerate(result.individual):\n    detector_name = ensemble.detectors[i].name\n    print(f\"  {detector_name}: {s:.4f}\")\n\n# Check for any failures\nif result.failures:\n    print(\"Failures:\", result.failures)\n</code></pre>"},{"location":"architecture/","title":"Architecture","text":""},{"location":"architecture/#overview","title":"Overview","text":"<p>PriorPatch uses a modular, plugin-based architecture that separates concerns and makes the system easily extensible.</p>"},{"location":"architecture/#core-components","title":"Core Components","text":""},{"location":"architecture/#1-detector-interface-detectorinterface","title":"1. Detector Interface (<code>DetectorInterface</code>)","text":"<p>The foundation of the system is the abstract <code>DetectorInterface</code> class:</p> <pre><code>class DetectorInterface(ABC):\n    name = 'base_detector'\n\n    @abstractmethod\n    def score(self, patch: np.ndarray) -&gt; float:\n        raise NotImplementedError\n</code></pre> <p>All forensic detectors must:</p> <ul> <li>Inherit from <code>DetectorInterface</code></li> <li>Implement the <code>score()</code> method</li> <li>Define a unique <code>name</code> attribute</li> </ul>"},{"location":"architecture/#2-registry-pattern","title":"2. Registry Pattern","text":"<p>The registry system (<code>registry.py</code>) provides automatic detector discovery:</p> <pre><code>@register_detector\nclass MyDetector(DetectorInterface):\n    name = 'my_detector'\n    # ...\n</code></pre> <p>Benefits:</p> <ul> <li>Automatic registration: Detectors self-register on import</li> <li>Decoupling: Core code doesn't need to know about specific detectors</li> <li>Extensibility: Add new detectors without modifying core code</li> </ul>"},{"location":"architecture/#3-ensemble-manager","title":"3. Ensemble Manager","text":"<p>The <code>Ensemble</code> class orchestrates multiple detectors:</p> <p>Key Responsibilities:</p> <ul> <li>Load detector configuration from JSON</li> <li>Instantiate detector instances</li> <li>Score patches using all detectors</li> <li>Normalize and combine scores</li> <li>Generate spatial heatmaps</li> </ul> <p>Scoring Pipeline:</p> <pre><code>Image -&gt; Patches -&gt; [Detector 1, Detector 2, ..., Detector N]\n                           |\n                           v\n                    Individual Scores\n                           |\n                           v\n                    Min-Max Normalization\n                           |\n                           v\n                    Weighted Average\n                           |\n                           v\n                    Combined Score -&gt; Heatmap\n</code></pre>"},{"location":"architecture/#4-configuration-system","title":"4. Configuration System","text":"<p>JSON-based configuration (<code>config/detectors.json</code>):</p> <pre><code>{\n  \"enabled_detectors\": [\"color_stats\", \"neighbor_consistency\", ...],\n  \"detector_weights\": {\n    \"color_stats\": 1.0,\n    \"neighbor_consistency\": 1.2,\n    ...\n  }\n}\n</code></pre>"},{"location":"architecture/#design-patterns","title":"Design Patterns","text":""},{"location":"architecture/#plugin-architecture","title":"Plugin Architecture","text":"<ul> <li>Purpose: Enable runtime extensibility</li> <li>Implementation: Registry + decorator pattern</li> <li>Benefit: Add detectors without modifying core code</li> </ul>"},{"location":"architecture/#strategy-pattern","title":"Strategy Pattern","text":"<ul> <li>Purpose: Interchangeable detection algorithms</li> <li>Implementation: <code>DetectorInterface</code> abstraction</li> <li>Benefit: Swap/combine detection strategies</li> </ul>"},{"location":"architecture/#template-method","title":"Template Method","text":"<ul> <li>Purpose: Standardize analysis workflow</li> <li>Implementation: <code>Ensemble.score_image()</code> pipeline</li> <li>Benefit: Consistent processing across detectors</li> </ul>"},{"location":"architecture/#data-flow","title":"Data Flow","text":"<pre><code>1. User Input (CLI or API)\n        |\n        v\n2. Load Configuration\n        |\n        v\n3. Initialize Ensemble\n        |\n        v\n4. Load Image\n        |\n        v\n5. Extract Patches (sliding window)\n        |\n        v\n6. For Each Patch:\n   - Score with all detectors\n   - Normalize scores (z-score)\n   - Combine with weights\n        |\n        v\n7. Generate Heatmap\n        |\n        v\n8. Output Results (visualization + JSON)\n</code></pre>"},{"location":"architecture/#module-structure","title":"Module Structure","text":"<pre><code>priorpatch/\n|-- __init__.py          # Package initialization, exports\n|-- cli.py               # Command-line interface\n|-- core.py              # Ensemble logic\n|-- utils.py             # I/O and visualization helpers\n|-- gpu_backend.py       # GPU acceleration (CuPy) with CPU fallback\n+-- detectors/           # Auto-discovered detector plugins\n    |-- base.py          # Abstract interface\n    |-- registry.py      # Plugin registry\n    |-- color_stats.py   # RGB correlation\n    |-- neighbor_consistency.py\n    |-- fft_dct.py       # Frequency analysis (GPU-accelerated)\n    |-- residual_energy.py\n    |-- dct_cooccurrence.py\n    |-- benford_law.py   # DCT coefficient analysis\n    |-- cfa_artifact.py  # Camera sensor artifacts\n    |-- chromatic_aberration.py\n    |-- copy_move.py     # Duplicated region detection\n    |-- ela.py           # Error Level Analysis\n    |-- gan_fingerprint.py\n    |-- jpeg_ghost.py\n    |-- lbp_texture.py\n    |-- lighting_consistency.py\n    |-- noise_consistency.py\n    +-- prnu_wavelet.py  # Sensor noise analysis\n</code></pre>"},{"location":"architecture/#extensibility-points","title":"Extensibility Points","text":""},{"location":"architecture/#adding-a-new-detector","title":"Adding a New Detector","text":"<ol> <li>Create file in <code>detectors/</code></li> <li>Inherit from <code>DetectorInterface</code></li> <li>Implement <code>score()</code> method</li> <li>Add <code>@register_detector</code> decorator</li> <li>Update configuration file</li> </ol>"},{"location":"architecture/#adding-a-new-score-combination-method","title":"Adding a New Score Combination Method","text":"<p>Modify <code>Ensemble.score_patch()</code> to implement:</p> <ul> <li>Different normalization schemes</li> <li>Alternative voting/fusion methods</li> <li>Confidence weighting</li> <li>Outlier handling</li> </ul>"},{"location":"architecture/#adding-new-output-formats","title":"Adding New Output Formats","text":"<p>Extend <code>utils.py</code> with:</p> <ul> <li>Different visualization styles</li> <li>Export to other formats (CSV, XML, etc.)</li> <li>Interactive visualizations</li> </ul>"},{"location":"architecture/#performance-considerations","title":"Performance Considerations","text":""},{"location":"architecture/#current-approach","title":"Current Approach","text":"<ul> <li>Patch extraction: Sliding window with configurable stride</li> <li>Processing: Sequential (single-threaded)</li> <li>Memory: Loads entire image into memory</li> </ul>"},{"location":"architecture/#optimization-opportunities","title":"Optimization Opportunities","text":"<ul> <li>Multiprocessing: Parallelize patch scoring</li> <li>Vectorization: Process multiple patches simultaneously</li> <li>Streaming: Process image in chunks for large files</li> <li>Caching: Cache detector computations for overlapping regions</li> </ul>"},{"location":"architecture/#testing-strategy","title":"Testing Strategy","text":"<ul> <li>Unit tests: Individual detector logic</li> <li>Integration tests: Ensemble coordination</li> <li>End-to-end tests: Full pipeline with sample images</li> <li>Regression tests: Ensure consistent results across versions</li> </ul>"},{"location":"detectors/","title":"Detectors","text":"<p>Each detector looks for different types of manipulation artifacts. Here's what they do and when they're useful.</p>"},{"location":"detectors/#color-stats","title":"Color Stats","text":"<p>What it checks: RGB channel correlations</p> <p>How it works: In real photos, color channels are correlated (R-G around 0.9, G-B around 0.9, R-B around 0.85). That's just how light works. When you edit colors, these relationships often break.</p> <p>Good for:</p> <ul> <li>Color grading inconsistencies</li> <li>Spliced regions from different lighting</li> <li>Unnatural color manipulation</li> </ul> <p>Bad for:</p> <ul> <li>Grayscale images</li> <li>Images that are naturally weird (intentional artistic color effects)</li> </ul> <p>Example: If you paste a person from a sunny photo into an overcast scene, the RGB correlations in the pasted region won't match.</p>"},{"location":"detectors/#neighbor-consistency","title":"Neighbor Consistency","text":"<p>What it checks: Pixel-to-neighbor relationships</p> <p>How it works: Predicts each pixel from its 8 neighbors. In natural images, this works pretty well. Splice boundaries and edited regions often fail this test.</p> <p>Good for:</p> <ul> <li>Copy-paste detection</li> <li>Splice boundaries</li> <li>Inpainting artifacts</li> </ul> <p>Bad for:</p> <ul> <li>Genuine edges and textures (can false-positive)</li> </ul> <p>Example: When you copy-paste an object, the boundary pixels don't match their new neighbors as well as they should.</p>"},{"location":"detectors/#fftdct","title":"FFT/DCT","text":"<p>What it checks: Frequency domain patterns</p> <p>How it works: Natural images follow a ~1/f^2 power law in frequency space. Resampling, JPEG compression, and synthetic generation mess this up. Also catches periodic patterns that shouldn't be there.</p> <p>Good for:</p> <ul> <li>Detecting resizing/rotation</li> <li>JPEG compression inconsistencies</li> <li>AI-generated content (sometimes)</li> <li>Periodic artifacts from generation</li> </ul> <p>Bad for:</p> <ul> <li>Small patches (needs at least 16x16)</li> <li>Genuinely textured regions</li> </ul> <p>Example: If part of an image was resized, it'll have different frequency characteristics than the rest.</p>"},{"location":"detectors/#residual-energy","title":"Residual Energy","text":"<p>What it checks: High-frequency noise levels</p> <p>How it works: Removes low-frequency content with Gaussian blur, measures what's left. Real photos have sensor noise and fine texture. Over-edited or AI-generated regions are often too smooth.</p> <p>Good for:</p> <ul> <li>Detecting smoothing/blurring</li> <li>AI-generated backgrounds (often too clean)</li> <li>Over-processed regions</li> </ul> <p>Bad for:</p> <ul> <li>Naturally smooth areas (sky, walls)</li> <li>Out-of-focus regions</li> </ul> <p>Example: AI-generated backgrounds often lack the natural sensor noise present in real photos.</p>"},{"location":"detectors/#dct-co-occurrence","title":"DCT Co-occurrence","text":"<p>What it checks: JPEG compression patterns</p> <p>How it works: Analyzes 8x8 DCT block coefficients. Images with consistent JPEG history have consistent patterns. Splicing from different sources or double compression creates mismatches.</p> <p>Good for:</p> <ul> <li>Detecting regions from different images</li> <li>Double JPEG compression</li> <li>Mixed compression quality</li> </ul> <p>Bad for:</p> <ul> <li>Uncompressed images (less useful)</li> <li>Images with complex JPEG history</li> </ul> <p>Example: If you paste a high-quality JPEG face onto a low-quality background, the DCT patterns won't match.</p>"},{"location":"detectors/#prnu-stub","title":"PRNU (Stub)","text":"<p>What it checks: Sensor noise patterns</p> <p>Status: ! Currently a placeholder - just uses gradient magnitude</p> <p>How it should work: Real PRNU extracts camera sensor fingerprints using wavelet denoising. Each camera has a unique noise pattern. Manipulated regions either lack this or have mismatched patterns.</p> <p>Current implementation: Just measures gradient magnitude as a proxy for high-frequency content.</p> <p>TODO: Replace with proper wavelet-based PRNU extraction</p> <p>Why it matters: When implemented properly, PRNU is one of the most reliable forensic techniques. But it's also computationally expensive.</p>"},{"location":"detectors/#jpeg-ghost","title":"JPEG Ghost","text":"<p>What it checks: JPEG recompression artifacts</p> <p>How it works: Recompresses the patch at various JPEG quality levels (50-95) and measures the difference from the original. If a region was originally compressed at quality Q, recompressing at Q produces minimal change. Different regions from different JPEG sources will have different \"ghost\" patterns.</p> <p>Good for:</p> <ul> <li>Spliced images from multiple JPEG sources</li> <li>Copy-paste from different quality images</li> <li>Detecting manipulation in JPEG images</li> </ul> <p>Bad for:</p> <ul> <li>Uncompressed source images</li> <li>Images with heavy post-processing</li> <li>AI-generated images (they haven't been through JPEG)</li> </ul> <p>Example: If you paste a face from a high-quality JPEG (Q=90) into a low-quality background (Q=70), the JPEG ghost detector will show inconsistent patterns.</p>"},{"location":"detectors/#gan-fingerprint","title":"GAN Fingerprint","text":"<p>What it checks: Neural network upsampling artifacts</p> <p>How it works: GANs and AI generators often use transposed convolutions for upsampling, which leaves checkerboard patterns in the frequency domain. This detector looks at FFT patterns for:</p> <ul> <li>Periodic peaks at quarter/half frequencies (from 2x/4x upsampling)</li> <li>Spectral slope deviation from natural 1/f pattern</li> <li>Unusual frequency symmetry</li> </ul> <p>Good for:</p> <ul> <li>Detecting AI-generated images (DALL-E, Midjourney, Stable Diffusion)</li> <li>GAN-generated faces</li> <li>Neural network-based upscaling artifacts</li> </ul> <p>Bad for:</p> <ul> <li>Real photographs</li> <li>Traditional edits (copy-paste, color correction)</li> <li>Very small patches</li> </ul> <p>Example: GAN-generated faces often have telltale periodic patterns in their frequency spectrum that real camera images don't produce.</p>"},{"location":"detectors/#noise-consistency","title":"Noise Consistency","text":"<p>What it checks: Unnatural noise patterns</p> <p>How it works: Real cameras produce consistent sensor noise across the entire image - typically Gaussian/Poisson distributed and correlated across RGB channels. AI-generated images often have:</p> <ul> <li>Regions that are too smooth (no noise)</li> <li>Inconsistent noise levels in different areas</li> <li>Wrong noise distribution (not Gaussian)</li> <li>Uncorrelated noise between color channels</li> </ul> <p>This detector measures noise variance, distribution shape (skewness, kurtosis), regional consistency, and cross-channel correlation.</p> <p>Good for:</p> <ul> <li>AI-generated images (often too clean)</li> <li>Heavily processed/inpainted regions</li> <li>Synthetic backgrounds</li> </ul> <p>Bad for:</p> <ul> <li>High-ISO photos (legitimate heavy noise)</li> <li>Professionally denoised photos</li> <li>Very smooth natural scenes (sky, water)</li> </ul> <p>Example: An AI-generated person might have perfectly smooth skin with no sensor noise, while the background has some noise - this inconsistency is suspicious.</p>"},{"location":"detectors/#benfords-law","title":"Benford's Law","text":"<p>What it checks: First-digit distribution in DCT coefficients</p> <p>How it works: Benford's Law says that in real-world data, the first digit isn't evenly distributed - 1 appears more than 2, 2 more than 3, etc. DCT coefficients from real photos follow this pattern. Edited and AI images often don't.</p> <p>Good for:</p> <ul> <li>General manipulation detection</li> <li>AI-generated images</li> <li>Any kind of synthetic content</li> </ul> <p>Bad for:</p> <ul> <li>Very small patches</li> <li>Heavily textured images</li> </ul> <p>Research: Achieves ~90% F1-score according to published studies. One of the most mathematically robust forensic techniques.</p>"},{"location":"detectors/#cfa-artifact-demosaicing","title":"CFA Artifact (Demosaicing)","text":"<p>What it checks: Presence of Bayer pattern demosaicing artifacts</p> <p>How it works: Real cameras have Bayer sensors - each pixel only sees one color (R, G, or B). The camera fills in the missing colors through interpolation (demosaicing), which creates specific patterns between pixels. AI images are made directly in RGB, so they don't have these patterns.</p> <p>Good for:</p> <ul> <li>AI-generated images (most reliable single detector)</li> <li>Any synthetic content</li> <li>Distinguishing real cameras from computer graphics</li> </ul> <p>Bad for:</p> <ul> <li>Images with heavy post-processing</li> <li>Specific camera brands with unusual CFA patterns</li> </ul> <p>Why it's powerful: AI can't fake what happens inside a real camera sensor. This physical difference is really hard to get around - probably the best single feature for catching AI images.</p>"},{"location":"detectors/#lbp-texture","title":"LBP Texture","text":"<p>What it checks: Local texture patterns</p> <p>How it works: LBP compares each pixel to its 8 neighbors - brighter neighbor = 1, darker = 0. This gives an 8-bit pattern per pixel. Real images have certain patterns that show up often; AI images tend to have more uniform or weird distributions.</p> <p>Good for:</p> <ul> <li>Deepfakes and AI-generated faces</li> <li>General AI detection</li> <li>Texture-based manipulation</li> </ul> <p>Bad for:</p> <ul> <li>Smooth natural scenes</li> <li>Very small patches</li> </ul> <p>Research: LBP-based methods achieve 83-99% accuracy on deepfake datasets.</p>"},{"location":"detectors/#chromatic-aberration","title":"Chromatic Aberration","text":"<p>What it checks: Lens chromatic aberration consistency</p> <p>How it works: Real lenses can't focus all colors to the same spot - red and blue shift slightly in opposite directions, especially near the edges. AI images don't go through real optics, so they either have no color fringing or it looks wrong.</p> <p>Good for:</p> <ul> <li>AI-generated images</li> <li>Detecting spliced regions with different CA patterns</li> <li>Source identification</li> </ul> <p>Bad for:</p> <ul> <li>Images with CA already corrected</li> <li>Low-contrast images with few edges</li> </ul>"},{"location":"detectors/#prnu-wavelet","title":"PRNU Wavelet","text":"<p>What it checks: Sensor noise patterns using wavelet denoising</p> <p>How it works: Each camera sensor has unique manufacturing imperfections that create a Photo Response Non-Uniformity (PRNU) - a consistent noise pattern in all images from that camera. This detector extracts the noise residual using wavelet-based denoising and analyzes its characteristics. AI images lack real sensor noise patterns.</p> <p>Good for:</p> <ul> <li>AI-generated images (no real sensor noise)</li> <li>Heavily processed images</li> <li>Source camera identification</li> </ul> <p>Bad for:</p> <ul> <li>High-ISO photos (strong legitimate noise)</li> <li>Images with artificial noise added</li> </ul>"},{"location":"detectors/#comparison","title":"Comparison","text":"Detector Speed Best For Weakness AI Detection color_stats Fast Color edits Grayscale images Low neighbor_consistency Fast Splice boundaries Genuine edges Low fft_dct Slow Resampling, JPEG Small patches Medium residual_energy Medium Smoothing, AI gen Naturally smooth areas Medium dct_cooccurrence Medium JPEG inconsistencies Uncompressed images Low ela Medium JPEG manipulation Uncompressed images Medium lighting_consistency Medium Composites, splicing Multiple light sources Medium copy_move Slow Duplicated regions Small patches Medium jpeg_ghost Slow JPEG splicing Uncompressed/AI images Low gan_fingerprint Medium AI upsampling Real photos High noise_consistency Medium AI-generated/smooth High-ISO photos High benford_law Medium All manipulations Small patches Very High cfa_artifact Fast AI detection Post-processed Highest lbp_texture Medium Deepfakes, AI Smooth scenes Very High chromatic_aberration Medium AI, splicing CA-corrected High prnu_wavelet Slow AI, source ID High-ISO High"},{"location":"detectors/#using-them-together","title":"Using them together","text":"<p>The ensemble combines all detectors using z-score normalization and weighted averaging. This helps because:</p> <ul> <li>Different manipulations leave different traces</li> <li>One detector's false positive might be corrected by others</li> <li>You can weight detectors based on what you trust more</li> </ul> <p>Example config:</p> <pre><code>{\n  \"enabled_detectors\": [\"color_stats\", \"fft_dct\", \"neighbor_consistency\"],\n  \"detector_weights\": {\n    \"fft_dct\": 2.0,           // trust frequency analysis more\n    \"color_stats\": 1.0,\n    \"neighbor_consistency\": 0.5   // less reliable in this dataset\n  }\n}\n</code></pre>"},{"location":"detectors/#adding-your-own","title":"Adding your own","text":"<p>See <code>CONTRIBUTING.md</code> for how to add a new detector. It's pretty straightforward - just implement the <code>score()</code> method and register it. With auto-discovery, you just drop a file in <code>priorpatch/detectors/</code> and it's automatically loaded.</p> <p>Some ideas for new detectors:</p> <ul> <li>Shadow direction consistency</li> <li>Perspective/vanishing point consistency</li> <li>Reflection analysis</li> <li>Metadata consistency checking</li> </ul>"},{"location":"detectors/#references","title":"References","text":"<p>These algorithms are based on various forensics papers:</p> <ul> <li>Popescu &amp; Farid: Copy-move forgery detection, CFA artifact detection</li> <li>Lukas et al: PRNU-based camera identification (IEEE Trans. IFS, 2006)</li> <li>Farid: Frequency analysis for manipulation detection</li> <li>Mahdian &amp; Saic: Using inconsistencies for detection</li> <li>Fu et al: Benford's Law for JPEG coefficients (2007)</li> <li>Johnson &amp; Farid: Chromatic aberration for forgery detection (2006)</li> <li>Ojala et al: Local Binary Patterns for texture classification</li> <li>Bonettini et al: Benford's Law for GAN detection (2020)</li> </ul> <p>Full references in academic papers about image forensics.</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.8 or higher</li> <li>pip package manager</li> <li>(Optional) Virtual environment</li> </ul>"},{"location":"installation/#quick-install","title":"Quick Install","text":""},{"location":"installation/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone https://github.com/jayashankarvr/priorpatch.git\ncd priorpatch\n</code></pre>"},{"location":"installation/#2-create-virtual-environment-recommended","title":"2. Create Virtual Environment (Recommended)","text":"<p>Using venv:</p> <pre><code>python -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n</code></pre> <p>Using conda:</p> <pre><code>conda create -n priorpatch python=3.10\nconda activate priorpatch\n</code></pre>"},{"location":"installation/#3-install-dependencies","title":"3. Install Dependencies","text":"<pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"installation/#4-install-priorpatch","title":"4. Install PriorPatch","text":"<p>Development mode (editable install):</p> <pre><code>pip install -e .\n</code></pre> <p>Regular install:</p> <pre><code>pip install .\n</code></pre>"},{"location":"installation/#verify-installation","title":"Verify Installation","text":"<p>Check that PriorPatch is installed correctly:</p> <pre><code>priorpatch --help\n</code></pre> <p>You should see the help message with available commands.</p> <p>Test with sample image:</p> <pre><code>priorpatch analyze --input examples/sample_input.png --outdir test_output/\n</code></pre>"},{"location":"installation/#dependencies","title":"Dependencies","text":"<p>PriorPatch requires the following packages:</p>"},{"location":"installation/#core-dependencies","title":"Core Dependencies","text":"<ul> <li>numpy (&gt;=1.21.0): Numerical computing</li> <li>Pillow (&gt;=9.0.0): Image loading/saving</li> <li>matplotlib (&gt;=3.5.0): Visualization and heatmap generation</li> <li>scipy (&gt;=1.7.0): Signal processing (FFT, DCT, filters)</li> </ul>"},{"location":"installation/#documentation-optional","title":"Documentation (Optional)","text":"<ul> <li>mkdocs (&gt;=1.4.0): Documentation site generator</li> <li>mkdocs-material (&gt;=9.0.0): Material theme for MkDocs</li> </ul>"},{"location":"installation/#testing-optional","title":"Testing (Optional)","text":"<ul> <li>pytest (&gt;=7.0.0): Testing framework</li> <li>pytest-cov (&gt;=4.0.0): Coverage reporting</li> </ul>"},{"location":"installation/#installation-methods","title":"Installation Methods","text":""},{"location":"installation/#method-1-development-install-recommended-for-contributors","title":"Method 1: Development Install (Recommended for Contributors)","text":"<p>This method creates a symlink, so code changes take effect immediately:</p> <pre><code>git clone https://github.com/jayashankarvr/priorpatch.git\ncd priorpatch\npip install -e .[dev]\n</code></pre>"},{"location":"installation/#method-2-user-install","title":"Method 2: User Install","text":"<p>For end users who just want to use the tool:</p> <pre><code>git clone https://github.com/jayashankarvr/priorpatch.git\ncd priorpatch\npip install .\n</code></pre>"},{"location":"installation/#method-3-install-from-source-tarball","title":"Method 3: Install from Source Tarball","text":"<pre><code># Download source tarball\nwget https://github.com/jayashankarvr/priorpatch/archive/v0.1.0.tar.gz\ntar -xzf v0.1.0.tar.gz\ncd priorpatch-0.1.0\npip install .\n</code></pre>"},{"location":"installation/#optional-components","title":"Optional Components","text":""},{"location":"installation/#install-with-development-tools","title":"Install with Development Tools","text":"<pre><code>pip install -e .[dev]\n</code></pre> <p>This includes pytest, coverage, and documentation tools.</p>"},{"location":"installation/#install-documentation-tools-only","title":"Install Documentation Tools Only","text":"<pre><code>pip install mkdocs mkdocs-material\n</code></pre> <p>Then build and serve documentation:</p> <pre><code>mkdocs serve\n</code></pre> <p>Visit http://localhost:8000 to view docs.</p>"},{"location":"installation/#platform-specific-notes","title":"Platform-Specific Notes","text":""},{"location":"installation/#linux","title":"Linux","text":"<p>No special requirements. Standard installation should work.</p>"},{"location":"installation/#macos","title":"macOS","text":"<p>If you encounter issues with scipy:</p> <pre><code># Install Xcode command line tools\nxcode-select --install\n\n# Install via Homebrew (alternative)\nbrew install python\npip install -r requirements.txt\n</code></pre>"},{"location":"installation/#windows","title":"Windows","text":"<p>Option 1: Use Anaconda/Miniconda (Recommended)</p> <p>Anaconda comes with pre-compiled scientific packages:</p> <pre><code>conda install numpy scipy matplotlib pillow\npip install .\n</code></pre> <p>Option 2: Use Windows Subsystem for Linux (WSL)</p> <p>Install WSL and follow Linux instructions.</p> <p>Option 3: Native Windows Install</p> <p>Ensure Visual C++ Build Tools are installed if you encounter compilation errors:</p> <ul> <li>Download from: https://visualstudio.microsoft.com/visual-cpp-build-tools/</li> </ul>"},{"location":"installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"installation/#import-errors","title":"Import Errors","text":"<p>Problem: <code>ModuleNotFoundError: No module named 'priorpatch'</code></p> <p>Solution:</p> <pre><code># Ensure you're in the correct environment\npip install -e .\n</code></pre>"},{"location":"installation/#scipy-installation-issues","title":"scipy Installation Issues","text":"<p>Problem: scipy fails to install or compile</p> <p>Solution: Use conda or pre-built wheels</p> <pre><code>conda install scipy\n# OR\npip install --only-binary :all: scipy\n</code></pre>"},{"location":"installation/#permission-errors","title":"Permission Errors","text":"<p>Problem: Permission denied during installation</p> <p>Solution: Use virtual environment or <code>--user</code> flag</p> <pre><code>pip install --user -e .\n</code></pre>"},{"location":"installation/#version-conflicts","title":"Version Conflicts","text":"<p>Problem: Dependency version conflicts</p> <p>Solution: Use fresh virtual environment</p> <pre><code>python -m venv fresh_env\nsource fresh_env/bin/activate\npip install -r requirements.txt\npip install -e .\n</code></pre>"},{"location":"installation/#updating-priorpatch","title":"Updating PriorPatch","text":""},{"location":"installation/#from-git-repository","title":"From Git Repository","text":"<pre><code>cd priorpatch\ngit pull origin main\npip install -e . --upgrade\n</code></pre>"},{"location":"installation/#check-current-version","title":"Check Current Version","text":"<pre><code>import priorpatch\nprint(priorpatch.__version__)\n</code></pre> <p>Or from command line:</p> <pre><code>pip show priorpatch\n</code></pre>"},{"location":"installation/#uninstalling","title":"Uninstalling","text":"<pre><code>pip uninstall priorpatch\n</code></pre> <p>To remove all dependencies as well:</p> <pre><code>pip freeze | grep -v \"^-e\" | xargs pip uninstall -y\n</code></pre>"},{"location":"installation/#docker-installation-advanced","title":"Docker Installation (Advanced)","text":"<p>Create a <code>Dockerfile</code>:</p> <pre><code>FROM python:3.10-slim\n\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY . .\nRUN pip install -e .\n\nCMD [\"priorpatch\", \"--help\"]\n</code></pre> <p>Build and run:</p> <pre><code>docker build -t priorpatch .\ndocker run -v $(pwd)/data:/data priorpatch analyze --input /data/image.jpg --outdir /data/output\n</code></pre>"},{"location":"installation/#next-steps","title":"Next Steps","text":"<p>After installation:</p> <ol> <li>Read the Usage Guide</li> <li>Try the example in <code>examples/</code></li> <li>Explore the API Reference</li> <li>Check out Detector Details</li> </ol>"},{"location":"limitations/","title":"Known Limitations","text":""},{"location":"limitations/#per-patch-normalization","title":"Per-Patch Normalization","text":"<p>Important: Scores are normalized per-patch, which means:</p>"},{"location":"limitations/#what-this-means","title":"What This Means","text":"<p>Each patch's detector scores are independently normalized to [0,1] before combining. This loses absolute scale information.</p>"},{"location":"limitations/#example","title":"Example","text":"<pre><code># Patch A: detectors return [0.1, 0.2, 0.3, 0.4, 0.5]\n# Normalized to: [0.0, 0.25, 0.5, 0.75, 1.0]\n\n# Patch B: detectors return [0.5, 0.6, 0.7, 0.8, 0.9]\n# Normalized to: [0.0, 0.25, 0.5, 0.75, 1.0]\n\n# Same normalized values, but Patch B is objectively more suspicious!\n</code></pre>"},{"location":"limitations/#implications","title":"Implications","text":"<ul> <li>Heatmap shows relative suspiciousness within each patch</li> <li>Cannot directly compare scores between different patches</li> <li>Patch with highest score might not be the most suspicious in absolute terms</li> <li>Entire image normalization happens afterward, but per-patch info is already lost</li> </ul>"},{"location":"limitations/#why-this-design","title":"Why This Design?","text":"<ul> <li>Combines detectors with different output ranges</li> <li>Prevents one high-magnitude detector from dominating</li> <li>Standard practice in ensemble methods</li> </ul>"},{"location":"limitations/#alternatives-not-implemented","title":"Alternatives (Not Implemented)","text":"<ol> <li>Global normalization: Normalize across all patches (requires two passes)</li> <li>Calibration: Pre-compute detector ranges on training data</li> <li>Quantile normalization: Use percentile-based scaling</li> </ol>"},{"location":"limitations/#recommendations","title":"Recommendations","text":"<ul> <li>Use heatmap to identify regions of interest</li> <li>Don't rely on absolute score values</li> <li>Compare patterns, not numbers</li> <li>Always manually inspect flagged regions</li> </ul>"},{"location":"limitations/#patch-overlap-artifacts","title":"Patch Overlap Artifacts","text":"<p>Default settings: <code>patch_size=64, stride=32</code> = 50% overlap</p>"},{"location":"limitations/#effect","title":"Effect","text":"<ul> <li>Corner pixels: Analyzed 1\u00d7</li> <li>Edge pixels: Analyzed 2\u00d7</li> <li>Center pixels: Analyzed 4\u00d7</li> </ul>"},{"location":"limitations/#impact","title":"Impact","text":"<ul> <li>Heatmap values not directly comparable across image</li> <li>Edges may appear different from center (not due to manipulation)</li> <li>More overlap = more averaged/smoothed results</li> </ul>"},{"location":"limitations/#workarounds","title":"Workarounds","text":"<ul> <li>Use <code>stride == patch_size</code> for no overlap (less smooth heatmap)</li> <li>Account for overlap when interpreting results</li> <li>Focus on relative differences, not absolute values</li> </ul>"},{"location":"limitations/#prnu-detector","title":"PRNU Detector","text":"<p>Current implementation is a stub using gradient magnitude, not proper sensor noise extraction.</p> <p>Not suitable for:</p> <ul> <li>Device identification</li> <li>Adversarial detection</li> <li>Production use</li> </ul> <p>Real PRNU requires:</p> <ul> <li>Wavelet-based denoising</li> <li>Multiple reference images</li> <li>Proper correlation analysis</li> </ul>"},{"location":"limitations/#memory-limitations","title":"Memory Limitations","text":"<p>Current implementation stores all patches in memory for multiprocessing.</p> <p>Memory usage:</p> <ul> <li>2048\u00d72048 image: ~50 MB of patches</li> <li>4K (3840\u00d73840): ~180 MB of patches</li> </ul> <p>Can cause issues with:</p> <ul> <li>Very large images (&gt;4K)</li> <li>Limited RAM systems</li> <li>Batch processing many images</li> </ul>"},{"location":"limitations/#detection-limitations","title":"Detection Limitations","text":""},{"location":"limitations/#works-well-for","title":"Works Well For","text":"<ul> <li>Copy-paste splicing</li> <li>Obvious resampling</li> <li>JPEG compression mismatches</li> <li>Over-smoothed regions</li> </ul>"},{"location":"limitations/#struggles-with","title":"Struggles With","text":"<ul> <li>High-quality professional edits</li> <li>Latest AI generation models (2025+)</li> <li>Naturally unusual images</li> <li>Heavy legitimate post-processing</li> <li>Adversarial attacks</li> </ul>"},{"location":"limitations/#not-designed-for","title":"Not Designed For","text":"<ul> <li>Video analysis</li> <li>Real-time detection</li> <li>Specific manipulation type classification</li> <li>Exact location of manipulation boundaries</li> </ul>"},{"location":"limitations/#performance","title":"Performance","text":"<ul> <li>Speed: Depends on image size and CPU cores</li> <li>No GPU acceleration: CPU-only implementation</li> <li>Large images: Can take minutes on single core</li> <li>Multiprocessing: Helps but has overhead</li> </ul> <p>Typical times (on modern CPU):</p> <ul> <li>512\u00d7512: 2-5 seconds</li> <li>1024\u00d71024: 10-20 seconds</li> <li>2048\u00d72048: 45-90 seconds</li> <li>4K: 3-5 minutes</li> </ul>"},{"location":"limitations/#thresholds","title":"Thresholds","text":"<p>No automatic thresholds for \"fake\" vs \"authentic\"</p> <ul> <li>Scores are relative, not absolute</li> <li>Depends on image content</li> <li>No ground truth calibration</li> <li>Requires manual interpretation</li> </ul> <p>Guidelines (not rules):</p> <ul> <li>0.0-0.3: Likely normal</li> <li>0.3-0.7: Ambiguous</li> <li>0.7-1.0: Suspicious</li> </ul> <p>But these vary by detector, image type, and content.</p>"},{"location":"limitations/#future-improvements","title":"Future Improvements","text":"<p>See roadmap for planned features that address these limitations.</p>"},{"location":"logging/","title":"Logging Configuration","text":"<p>PriorPatch uses Python's standard logging module. Here's how to configure it for your needs.</p>"},{"location":"logging/#cli-logging","title":"CLI Logging","text":"<p>Control log verbosity with the <code>--log-level</code> flag:</p> <pre><code># Minimal output (errors only)\npriorpatch analyze --input image.jpg --outdir results/ --log-level ERROR\n\n# Normal output (default)\npriorpatch analyze --input image.jpg --outdir results/ --log-level INFO\n\n# Verbose output (for debugging)\npriorpatch analyze --input image.jpg --outdir results/ --log-level DEBUG\n</code></pre>"},{"location":"logging/#python-api-logging","title":"Python API Logging","text":""},{"location":"logging/#basic-setup","title":"Basic Setup","text":"<pre><code>import logging\nfrom priorpatch import Ensemble, load_image\n\n# Configure logging\nlogging.basicConfig(\n    level=logging.INFO,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n)\n\n# Use PriorPatch\nensemble = Ensemble.from_config('config/detectors.json')\nimg = load_image('photo.jpg')\nresult = ensemble.score_image(img)\n</code></pre>"},{"location":"logging/#save-logs-to-file","title":"Save Logs to File","text":"<pre><code>import logging\n\n# Log to file\nlogging.basicConfig(\n    level=logging.DEBUG,\n    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n    filename='priorpatch.log',\n    filemode='w'\n)\n\n# Or log to both file and console\nlogger = logging.getLogger()\nlogger.setLevel(logging.INFO)\n\n# File handler\nfh = logging.FileHandler('priorpatch.log')\nfh.setLevel(logging.DEBUG)\n\n# Console handler\nch = logging.StreamHandler()\nch.setLevel(logging.INFO)\n\n# Formatter\nformatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\nfh.setFormatter(formatter)\nch.setFormatter(formatter)\n\nlogger.addHandler(fh)\nlogger.addHandler(ch)\n</code></pre>"},{"location":"logging/#filter-by-component","title":"Filter by Component","text":"<pre><code>import logging\n\n# Only show logs from specific detectors\nlogging.getLogger('priorpatch.detectors.color_stats').setLevel(logging.DEBUG)\nlogging.getLogger('priorpatch.detectors.fft_dct').setLevel(logging.WARNING)\n\n# Silence a noisy detector\nlogging.getLogger('priorpatch.detectors.copy_move').setLevel(logging.ERROR)\n\n# Core ensemble logs only\nlogging.getLogger('priorpatch.core').setLevel(logging.INFO)\n</code></pre>"},{"location":"logging/#log-levels-guide","title":"Log Levels Guide","text":"Level When to Use What You'll See DEBUG Debugging issues Detailed info: patch-by-patch processing, detector computations INFO Normal operation Progress updates, completion messages WARNING Important notices Detector failures, unusual inputs, performance issues ERROR Problems Critical failures, invalid inputs, unrecoverable errors"},{"location":"logging/#what-gets-logged","title":"What Gets Logged","text":""},{"location":"logging/#debug-level","title":"DEBUG Level","text":"<ul> <li>Individual patch processing</li> <li>Detector score calculations</li> <li>Image conversions</li> <li>Normalization details</li> </ul>"},{"location":"logging/#info-level","title":"INFO Level","text":"<ul> <li>Image loading</li> <li>Ensemble initialization</li> <li>Number of patches to process</li> <li>Heatmap generation</li> <li>File I/O operations</li> </ul>"},{"location":"logging/#warning-level","title":"WARNING Level","text":"<ul> <li>Image size mismatches</li> <li>Detector failures (&lt;50% patches)</li> <li>Path traversal attempts</li> <li>Config inconsistencies</li> </ul>"},{"location":"logging/#error-level","title":"ERROR Level","text":"<ul> <li>Missing files</li> <li>Invalid configurations</li> <li>High detector failure rates (&gt;50%)</li> <li>Critical processing errors</li> </ul>"},{"location":"logging/#examples","title":"Examples","text":""},{"location":"logging/#debug-a-specific-image","title":"Debug a Specific Image","text":"<pre><code>import logging\n\n# Enable debug logging\nlogging.basicConfig(level=logging.DEBUG)\n\nfrom priorpatch import Ensemble, load_image\n\nensemble = Ensemble.from_config('config/detectors.json')\nimg = load_image('problematic_image.jpg')\nresult = ensemble.score_image(img)\n\n# Check logs for any warnings or errors\n</code></pre>"},{"location":"logging/#quiet-mode-only-errors","title":"Quiet Mode (Only Errors)","text":"<pre><code>import logging\n\nlogging.basicConfig(level=logging.ERROR)\n\n# Now PriorPatch will only show errors, no progress updates\n</code></pre>"},{"location":"logging/#custom-format","title":"Custom Format","text":"<pre><code>import logging\n\nlogging.basicConfig(\n    level=logging.INFO,\n    format='[%(levelname)s] %(message)s',  # Simple format\n    datefmt='%H:%M:%S'\n)\n</code></pre>"},{"location":"logging/#troubleshooting","title":"Troubleshooting","text":""},{"location":"logging/#no-logs-appearing","title":"No Logs Appearing?","text":"<p>If you don't see any logs:</p> <ol> <li>Check that logging is configured before importing priorpatch</li> <li>Make sure log level is not set too high (ERROR will hide INFO messages)</li> <li>Verify no other library is overriding the logging config</li> </ol>"},{"location":"logging/#too-much-output","title":"Too Much Output?","text":"<pre><code># Reduce verbosity\nlogging.getLogger('priorpatch').setLevel(logging.WARNING)\n\n# Or disable progress bars\nimport os\nos.environ['TQDM_DISABLE'] = '1'\n</code></pre>"},{"location":"logging/#performance-impact","title":"Performance Impact","text":"<p>Logging has minimal performance impact:</p> <ul> <li>INFO level: &lt; 1% overhead</li> <li>DEBUG level: 2-5% overhead (due to detailed per-patch logs)</li> </ul> <p>For production use, stick with INFO or WARNING level.</p>"},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#command-line-interface","title":"Command Line Interface","text":""},{"location":"usage/#basic-analysis","title":"Basic Analysis","text":"<pre><code>priorpatch analyze --input examples/sample_input.png --outdir outputs\n</code></pre>"},{"location":"usage/#with-individual-detector-results","title":"With Individual Detector Results","text":"<pre><code>priorpatch analyze --input image.jpg --outdir outputs --save-individual\n</code></pre> <p>This will create:</p> <ul> <li><code>outputs/heatmap_combined.png</code> - Ensemble result</li> <li><code>outputs/individual_detectors/color_stats_heatmap.png</code> - Color detector only</li> <li><code>outputs/individual_detectors/fft_dct_heatmap.png</code> - Frequency detector only</li> <li>... (one for each detector)</li> <li><code>outputs/summary.json</code> - Scores from all detectors</li> </ul>"},{"location":"usage/#batch-processing-directory","title":"Batch Processing (Directory)","text":"<pre><code># Analyze all images in a directory (recursive)\npriorpatch analyze --input-dir photos/ --outdir results/\n\n# Using glob pattern\npriorpatch analyze --input \"photos/*.jpg\" --outdir results/\n\n# With individual detector heatmaps for each image\npriorpatch analyze --input-dir photos/ --outdir results/ --save-individual\n</code></pre> <p>This will:</p> <ul> <li>Create a subfolder per image in the output directory</li> <li>Generate <code>batch_summary.json</code> with all results sorted by suspicion score</li> <li>Show the top 5 most suspicious images after processing</li> </ul>"},{"location":"usage/#custom-parameters","title":"Custom Parameters","text":"<pre><code>priorpatch analyze \\\n  --input image.jpg \\\n  --outdir results/ \\\n  --patch_size 32 \\\n  --stride 16 \\\n  --config custom_config.json \\\n  --save-individual \\\n  --log-level DEBUG\n</code></pre> <p>Available options:</p> <ul> <li><code>--input</code>: Single image file or glob pattern (e.g., <code>\"photos/*.jpg\"</code>)</li> <li><code>--input-dir</code>: Directory containing images (recursive)</li> <li><code>--patch_size</code>: Size of analysis patches (8-1024, default: 64)</li> <li><code>--stride</code>: Stride for patch extraction (minimum 1, default: 32)</li> <li><code>--log-level</code>: Logging verbosity (DEBUG, INFO, WARNING, ERROR)</li> </ul>"},{"location":"usage/#python-api","title":"Python API","text":""},{"location":"usage/#basic-usage","title":"Basic Usage","text":"<pre><code>from priorpatch.core import Ensemble\nfrom priorpatch.utils import load_image, save_heatmap\n\n# Load image\nimg = load_image('examples/sample_input.png')\n\n# Create ensemble\nens = Ensemble.from_config('config/detectors.json')\n\n# Analyze image\nheatmap = ens.score_image(img, patch_size=64, stride=32)\n\n# Save result\nsave_heatmap(heatmap, img, 'output.png')\n</code></pre>"},{"location":"usage/#with-individual-detector-results_1","title":"With Individual Detector Results","text":"<pre><code>from priorpatch.core import Ensemble\nfrom priorpatch.utils import load_image, save_heatmap\n\nimg = load_image('image.jpg')\nens = Ensemble.from_config('config/detectors.json')\n\n# Get both combined and individual results\nresults = ens.score_image(\n    img, \n    patch_size=64, \n    stride=32,\n    return_individual=True  # Enable individual tracking\n)\n\n# Access results\ncombined_heatmap = results.combined\nindividual_heatmaps = results.individual\ndetector_names = results.detector_names\n\n# Save combined\nsave_heatmap(combined_heatmap, img, 'combined.png')\n\n# Save each detector's result\nfor name in detector_names:\n    detector_heatmap = individual_heatmaps[name]\n    save_heatmap(detector_heatmap, img, f'{name}.png')\n    print(f\"{name}: max_score={detector_heatmap.max():.4f}\")\n</code></pre>"},{"location":"usage/#analyzing-specific-regions","title":"Analyzing Specific Regions","text":"<pre><code># Extract a specific region (y:y+h, x:x+w)\nregion = img[100:200, 150:250]\n\n# Score the region with all detectors\ncombined_score, individual_scores = ens.score_patch(region)\n\nprint(f\"Combined score: {combined_score:.4f}\")\nprint(\"\\nIndividual detector scores:\")\nfor detector, score in zip(ens.detectors, individual_scores):\n    print(f\"  {detector.name}: {score:.4f}\")\n</code></pre>"},{"location":"usage/#comparing-detectors","title":"Comparing Detectors","text":"<pre><code>import numpy as np\n\n# Get individual results\nresults = ens.score_image(img, return_individual=True)\n\n# See which detector is most suspicious\nfor name in results.detector_names:\n    heat = results.individual[name]\n    print(f\"{name}: max={heat.max():.4f}, mean={heat.mean():.4f}\")\n\n# Find detector with highest max score\nmax_scores = {name: results.individual[name].max() \n              for name in results.detector_names}\nmost_suspicious = max(max_scores, key=max_scores.get)\nprint(f\"\\nMost suspicious detector: {most_suspicious}\")\n</code></pre>"},{"location":"usage/#understanding-results","title":"Understanding Results","text":""},{"location":"usage/#combined-heatmap","title":"Combined Heatmap","text":"<ul> <li>Shows ensemble decision (all detectors combined)</li> <li>Red areas: High anomaly score (suspicious)</li> <li>Blue/Green areas: Low anomaly score (normal)</li> <li>Score range: 0.0 (normal) to 1.0 (suspicious)</li> </ul>"},{"location":"usage/#individual-detector-heatmaps","title":"Individual Detector Heatmaps","text":"<ul> <li>Shows what each detector found</li> <li>Helps understand WHY something is flagged</li> <li>Different detectors detect different artifacts</li> </ul> <p>Example interpretation:</p> <ul> <li><code>fft_dct</code> high: Frequency anomalies (resampling, JPEG)</li> <li><code>color_stats</code> high: Unnatural color relationships</li> <li><code>neighbor_consistency</code> high: Splice boundaries</li> <li><code>residual_energy</code> high: Too smooth (edited/AI-generated)</li> </ul>"},{"location":"usage/#score-thresholds-guidelines","title":"Score Thresholds (Guidelines)","text":"Score Range Interpretation 0.0 - 0.3 Likely authentic 0.3 - 0.5 Mild suspicion 0.5 - 0.7 Moderate suspicion 0.7 - 0.9 High suspicion 0.9 - 1.0 Very high suspicion <p>Note: These are guidelines, not absolute thresholds. Always verify with multiple methods.</p>"},{"location":"usage/#advanced-usage","title":"Advanced Usage","text":""},{"location":"usage/#custom-detector-selection","title":"Custom Detector Selection","text":"<pre><code>from priorpatch.core import Ensemble\nfrom priorpatch.detectors.registry import get_detector_class\n\n# Manually select detectors\ndetectors = [\n    get_detector_class('color_stats')(),\n    get_detector_class('fft_dct')(),\n]\n\n# Custom weights\nweights = {\n    'color_stats': 2.0,  # Emphasize color analysis\n    'fft_dct': 1.5,\n}\n\nens = Ensemble(detectors, weights)\n</code></pre>"},{"location":"usage/#batch-processing","title":"Batch Processing","text":"<pre><code>import os\nfrom pathlib import Path\n\n# Process all images in a directory\ninput_dir = Path('images/')\noutput_dir = Path('results/')\noutput_dir.mkdir(exist_ok=True)\n\nens = Ensemble.from_config('config/detectors.json')\n\nfor img_path in input_dir.glob('*.jpg'):\n    print(f\"Processing: {img_path}\")\n\n    img = load_image(str(img_path))\n    results = ens.score_image(img, return_individual=True)\n\n    # Save combined result\n    out_path = output_dir / f\"{img_path.stem}_result.png\"\n    save_heatmap(results.combined, img, str(out_path))\n\n    print(f\"  Max score: {results.combined.max():.4f}\")\n</code></pre>"},{"location":"usage/#tips","title":"Tips","text":"<ol> <li>Patch Size:</li> <li>Smaller (32-64): More detail, slower</li> <li> <p>Larger (128+): Faster, less detail</p> </li> <li> <p>Stride:</p> </li> <li>Smaller: More overlap, better accuracy, slower</li> <li> <p>Larger: Faster, less overlap</p> </li> <li> <p>Individual Results:</p> </li> <li>Use when you need to understand WHY something is flagged</li> <li>Helps identify specific manipulation types</li> <li> <p>Good for debugging and analysis</p> </li> <li> <p>Multiprocessing:</p> </li> <li>Automatically enabled for images with &gt;10 patches</li> <li>Significant speedup on multi-core systems</li> <li> <p>Use <code>use_multiprocessing=True</code> in Python API</p> </li> <li> <p>Detector Weights:</p> </li> <li>Adjust based on your use case</li> <li>Higher weight = more influence on final score</li> <li> <p>Start with equal weights (1.0), tune based on results</p> </li> <li> <p>Progress Bars:</p> </li> <li>Install tqdm for progress indicators: <code>pip install tqdm</code></li> <li> <p>Optional but recommended for large images</p> </li> <li> <p>Error Handling:</p> </li> <li>Tool validates inputs and provides clear error messages</li> <li>Detector failures are logged and tracked</li> <li>If a detector fails on &gt;50% of patches, an error is logged</li> </ol>"}]}